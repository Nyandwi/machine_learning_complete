{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304ad719",
   "metadata": {
    "id": "304ad719"
   },
   "source": [
    "<a name='0'></a>\n",
    "# Neural Networks for Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a095ea",
   "metadata": {
    "id": "b6a095ea"
   },
   "source": [
    "### Contents \n",
    "\n",
    "* [1. Intro to Regression with TensorFlow](#1)\n",
    "* [2. Starting Simple: Fitting a Straight Line](#2)\n",
    "   * [2.1 Gathering the data](#2-1)\n",
    "   * [2.2 Looking in the data](#2-2)\n",
    "   * [2.3 Preparing the data for a model](#2-3)\n",
    "   * [2.4 Creating, Compiling and Training a model](#2-4)\n",
    "   * [2.5 Evaluating a model](#2-5)\n",
    "   * [2.6 Improving a model](#2-6)\n",
    "  \n",
    "\n",
    "* [3. Going Beyond: A Real world dataset](#3)\n",
    "   * [3.1 Gathering the data](#3-1)\n",
    "   * [3.2 Looking in the data](#3-2)\n",
    "   * [3.3 Preparing the data for a model](#3-3)\n",
    "   * [3.4 Creating, Compiling and Training a model](#3-4)\n",
    "   * [3.5 Evaluating a model](#3-5)\n",
    "   * [3.6 Saving a model](#3-6)\n",
    "   * [3.7 Final notes](#3-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AAqeb2v2jSWT",
   "metadata": {
    "id": "AAqeb2v2jSWT"
   },
   "source": [
    "<a name='1'></a>\n",
    "## Intro to Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hcDOlUdZxDGu",
   "metadata": {
    "id": "hcDOlUdZxDGu"
   },
   "source": [
    "We know neural networks in taking moonshots but they can also be used for regression problems. \n",
    "\n",
    "In regression task/problems, we are interested in predicting the a single or multiple continous numbers. \n",
    "\n",
    "Take an example of house price prediction. We can be given the properties/features of the house such as size, region, and number of bedrooms to predict the price of such house. This example is a single number prediction, also termed as `univariate regression`. \n",
    "\n",
    "Another example appears in object detection(recognizing & localizing image). In order to localize the object with the bounding box, you have got to find the coordinates of the object's center and the bounding box. The prediction of these coordinates is an example of predicting multiple values at once. It is usually termed as `multivariate regression`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jG7bLsj03uxw",
   "metadata": {
    "id": "jG7bLsj03uxw"
   },
   "source": [
    "Any typical architecture for a regression neural network will have common values or ranges of values of `hyperparameters` (hyperparameters are all parameters that you as engineer has to set, such as learning rate, number of layers, etc..). \n",
    "Let's discuss them. \n",
    "\n",
    "\n",
    "#### **Input, hidden, and Output Layers**\n",
    "\n",
    "The input layer usually has the neurons(or units) equivalent to the number of input features. For example, if our house dataset has 10 variables, 9 input training features, 1 target feature(price of house), then the input neurons will be 9. \n",
    "\n",
    "The number of hidden layers depend on the problem and the size of the dataset, but generally, it will be between 1 and 5. Same is true about the number of neurons in each hidden layer, it will depend on the problem & dataset size, but generally, neurons can be between 10 to 100. \n",
    "\n",
    "The number of neurons in output layer will depend on the problem. If you are predicting a single number, it will be 1. If you are predicting the coordinates of the object's center and bounding box during object detection, it will be 4 (because there are 4 coordinates, 2 for object's center, 2 for height/width of the box). \n",
    "\n",
    "\n",
    "#### **Activation Function**\n",
    "\n",
    "The choice of activation function depends on the problem, but in most cases, `relu` will work well in hidden layers. \n",
    "\n",
    "The activation function in the output layer is very specific on the goal of the problem. Unlike neural network classifiers that usually use [`sigmoid`](https://en.wikipedia.org/wiki/Sigmoid_function) or [`softmax`](https://en.wikipedia.org/wiki/Softmax_function), regressor doesn't need to have an activation since you want the output values as they are. That being said, you may want to prevent the negative values in the output layer. In that case, you can use [`ReLU`](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)). \n",
    "\n",
    "\n",
    "#### Training Loss Function\n",
    "\n",
    "The loss function used in regression is usually [`Mean Squared Error(MSE)`](https://en.wikipedia.org/wiki/Mean_squared_error). When you are aware that your dataset contain outliers, you can use [`Mean Absolute Error (MAE)`](https://en.wikipedia.org/wiki/Mean_absolute_error). MAE can potentialy be used in time series prediction since that type of data tends to have outliers.\n",
    "\n",
    "Another loss function that is used alot if [Huber loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/huber). It is combination of both MSE and MAE. \n",
    "\n",
    "#### Optimizer\n",
    "\n",
    "A good rule of thumb when choosing an optimizer is to start with [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam). There are other optimizers that you can try, such as SGD(Stockastic Gradient Descent), RMSProp, Nadam, etc...Learn more about them on [TensorFlow optimizer documentation page](https://www.tensorflow.org/api_docs/python/tf/optimizers). \n",
    "\n",
    "Below is a summary of hyerparameter best practices in neural network regressors.\n",
    "\n",
    "\n",
    "\n",
    "| **Hyperparameter** | **Typical value** |\n",
    "| --- | --- |\n",
    "| Neurons at input layer | 1 neuron per feature |\n",
    "| No of hidden layer(s) | depend on problem, start from 1 to 10 |\n",
    "| Neurons per hidden layer | depend on problem, generally 10 to 100 |\n",
    "| Neurons at input layer | depend on the desired result, 1 for univariate regression |\n",
    "| Activation in hidden layers| Relu or its variants(LeakyReLU, SeLU|\n",
    "| Activation in output layer |None in most cases|\n",
    "| Loss function | MSE or MAE |\n",
    "| Optimizer | SGD, Adam, RMSProp |\n",
    "\n",
    "*Table: Typical values of hyperparameters in neural network regressors*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8H7r9hKeHAeM",
   "metadata": {
    "id": "8H7r9hKeHAeM"
   },
   "source": [
    "There are many hyperparameters in neural networks and finding the best values of each and each can be overwhelming. \n",
    "\n",
    "In later notebooks, we will use [Keras Tuner](https://keras.io/keras_tuner/) to search the best hyperparameters whenever possible. It is nearly impossible to assume that a given value of hyperparamater will work well at first. We usually have to experiment with different values. \n",
    "\n",
    "Let's put all of the above into practice, starting simple, and later, taking a futher step into real world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9pEQ8VbkIRsO",
   "metadata": {
    "id": "9pEQ8VbkIRsO"
   },
   "source": [
    "<a name='2'></a>\n",
    "\n",
    "## 2. Starting Simple: Fitting a Straight Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I8spI9b6g-vy",
   "metadata": {
    "id": "I8spI9b6g-vy"
   },
   "source": [
    "One of the simplest things we can model is perhaps a linear equation(it has been proven that [neural networks can model any mathematical function](http://neuralnetworksanddeeplearning.com/chap4.html)). \n",
    "\n",
    "So, a linear equation forms a straight line. Its form is `y=aX+b` where a is coefficient (or `weight`) and b is intercept (or `bias`). \n",
    "\n",
    "Let's assume that we have this equation `y=2X+1` and we are interested in using neural networks to predict y given any value of X. \n",
    "\n",
    "But we will start with creating our data based off such equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AhILzCKOg9mu",
   "metadata": {
    "id": "AhILzCKOg9mu"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1  Gathering the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N5UGgGiOk7xO",
   "metadata": {
    "id": "N5UGgGiOk7xO"
   },
   "source": [
    "Let's first import the libraries. I will import `TensorFlow`, `NumPy` and `Matplolib` for plotting the straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "jhhUN8KYlHCd",
   "metadata": {
    "id": "jhhUN8KYlHCd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98AuRTg8lSPd",
   "metadata": {
    "id": "98AuRTg8lSPd"
   },
   "source": [
    "After we have imported all relevant libraries, it's time to create our data. We only have one input feature (`X`) and output label `y`. \n",
    "\n",
    "We can either create it with `tf.constant()` or `np.array()`. Both will work, but for convenience, let's use `tf.constant()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f6p8Csdl8Vc",
   "metadata": {
    "id": "7f6p8Csdl8Vc"
   },
   "outputs": [],
   "source": [
    "# Create input feature X\n",
    "\n",
    "X = tf.constant([-2,-1,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,10,12])\n",
    "\n",
    "# Create label y\n",
    "\n",
    "y = tf.constant([-3.0,-1.0,1.0,3.0,5.0,7.0,9.0,11.0,13.0,15.0,17.0,21.0,25.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nwPHdU4ZqUbK",
   "metadata": {
    "id": "nwPHdU4ZqUbK"
   },
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2  Looking in the Data\n",
    "\n",
    "It's always good to look in the data. This can be done in many ways and it depend on the kind of the dataset. If you're working with images, you might want to go through some images and their labels looking if there are no mislabelling. \n",
    "\n",
    "In structured data, or data in tabular form, you might have to visualize the distribution of individual features or plot their relationship. \n",
    "\n",
    "For us now, we have a simple data. Let's scatter plot X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "YKQFuvyLqkA6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "YKQFuvyLqkA6",
    "outputId": "d79a78c6-7c20-4061-e2b1-0c08fd352647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing X and y\n",
    "\n",
    "plt.plot(X,y) #This will plot a line\n",
    "plt.scatter(X,y) \n",
    "plt.annotate('y=2X+1', xy=(3,4))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "StLIYBqUu_pe",
   "metadata": {
    "id": "StLIYBqUu_pe"
   },
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3  Preparing data for the model\n",
    "\n",
    "Usually when working with real world datasets, we need to spend an enourmous amount of time preparing it. The type of things to be done depend on the kind of the dataset, but typically, it can be removing/filling missing values, scaling the features either with normalization or standardization, and so on. \n",
    "\n",
    "For now, we can leave our data as it is. In the next labs, we will see some real world datasets that needs extra work before feeding them to the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u8JV6HwXxcDM",
   "metadata": {
    "id": "u8JV6HwXxcDM"
   },
   "source": [
    "<a name='2-4'></a>\n",
    "### 2.4  Creating, Compiling and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-SfBQQunx710",
   "metadata": {
    "id": "-SfBQQunx710"
   },
   "source": [
    "We are going to create the model having a one layer, one neuron(or unit) and as the input data is a single number, we will set the `input_shape` to `[1]`. \n",
    "\n",
    "Later, we will explain everything we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sfadbvPlzFiO",
   "metadata": {
    "id": "sfadbvPlzFiO"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             \n",
    "                             keras.layers.Dense(units=1, input_shape=[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y-irJjCqzb0P",
   "metadata": {
    "id": "Y-irJjCqzb0P"
   },
   "source": [
    "And we can see the model summary. Model summary is essential for quick review of the model architecture. As you can see, we only have one dense layer, and 2 parameters(weight and bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "jqyr0pCwzeGy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqyr0pCwzeGy",
    "outputId": "bb1bac8c-e54f-4ba0-fb19-a0c4a50c7db0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pt6VEiYxz-GI",
   "metadata": {
    "id": "pt6VEiYxz-GI"
   },
   "source": [
    "The model that we created is called a  Sequential model. We create it by adding one layer after another. If we had many layers, it would be like a sequence or series of layers, one after another, from the input to the ouput. You can learn more about Sequential API [here](https://keras.io/api/models/sequential/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EUdQUMUp1O47",
   "metadata": {
    "id": "EUdQUMUp1O47"
   },
   "source": [
    "After we have created the model, all we have is an empty graphs. We need to do two more things, compiling and training/fitting the model to the presented data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "-6HLWEe62CBC",
   "metadata": {
    "id": "-6HLWEe62CBC"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GI77KEDn2Bac",
   "metadata": {
    "id": "GI77KEDn2Bac"
   },
   "source": [
    "The single most reason of why we compile the model is to specify the optimizer, loss function and the metrics that we want to track during training. \n",
    "\n",
    "During training, loss function will be used to measure the difference between the prediction and the actual output. Such difference is called `error`, but we want to measure the `the mean of squared error`, hence the name.\n",
    "\n",
    "`Error = Actual value â€“ Predicted value`. \n",
    "\n",
    "On the otherhand, optimizer is used to reduce the error between the actual output and predicted value. The optimizer will make continous guesses until the minimum error is reached. There are many optimizers, but for now let's use SGD (Stockastic Gradient Descent). In later labs, we will explore other optimizers. \n",
    "\n",
    "By fitting the model to the data, here are what happen:\n",
    "\n",
    "* The model iterate through each input data point and estimate prediction \n",
    "* The difference between the actual and predicted value or error is calculated by loss function\n",
    "* The error is minimized by optimizer as we go through the data\n",
    "* The above iteration continue until the number of epochs are reached. \n",
    "\n",
    "\n",
    "Let's see that in action, fitting the model to the data, calculating and reducing the error until we make 500 turns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pJ8gCQVK4CbR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJ8gCQVK4CbR",
    "outputId": "fac617e1-b6dd-475c-fe2b-9e4d75624c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 226.2254 - mse: 226.2254\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5842 - mse: 19.5842\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8814 - mse: 1.8814\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3613 - mse: 0.3613\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2273 - mse: 0.2273\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2121 - mse: 0.2121\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2071 - mse: 0.2071\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2031 - mse: 0.2031\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1992 - mse: 0.1992\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1954 - mse: 0.1954\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1917 - mse: 0.1917\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1880 - mse: 0.1880\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1844 - mse: 0.1844\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1809 - mse: 0.1809\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1774 - mse: 0.1774\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1741 - mse: 0.1741\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1707 - mse: 0.1707\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1675 - mse: 0.1675\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1643 - mse: 0.1643\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1612 - mse: 0.1612\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1581 - mse: 0.1581\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1551 - mse: 0.1551\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1521 - mse: 0.1521\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1492 - mse: 0.1492\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1464 - mse: 0.1464\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1436 - mse: 0.1436\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1408 - mse: 0.1408\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1381 - mse: 0.1381\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1355 - mse: 0.1355\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1329 - mse: 0.1329\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1304 - mse: 0.1304\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1279 - mse: 0.1279\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1255 - mse: 0.1255\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1231 - mse: 0.1231\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1207 - mse: 0.1207\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1184 - mse: 0.1184\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1162 - mse: 0.1162\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1139 - mse: 0.1139\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1118 - mse: 0.1118\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1096 - mse: 0.1096\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1075 - mse: 0.1075\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1055 - mse: 0.1055\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1035 - mse: 0.1035\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1015 - mse: 0.1015\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0996 - mse: 0.0996\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0977 - mse: 0.0977\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0958 - mse: 0.0958\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0940 - mse: 0.0940\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0922 - mse: 0.0922\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0904 - mse: 0.0904\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0887 - mse: 0.0887\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0870 - mse: 0.0870\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0854 - mse: 0.0854\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0837 - mse: 0.0837\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0821 - mse: 0.0821\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0806 - mse: 0.0806\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0790 - mse: 0.0790\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0775 - mse: 0.0775\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0760 - mse: 0.0760\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0746 - mse: 0.0746\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0732 - mse: 0.0732\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0718 - mse: 0.0718\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0704 - mse: 0.0704\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0691 - mse: 0.0691\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0664 - mse: 0.0664\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0652 - mse: 0.0652\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0639 - mse: 0.0639\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0627 - mse: 0.0627\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0615 - mse: 0.0615\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0603 - mse: 0.0603\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0592 - mse: 0.0592\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0581 - mse: 0.0581\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0570 - mse: 0.0570\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0559 - mse: 0.0559\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0548 - mse: 0.0548\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0538 - mse: 0.0538\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0517 - mse: 0.0517\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0507 - mse: 0.0507\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0498 - mse: 0.0498\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0488 - mse: 0.0488\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0479 - mse: 0.0479\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0470 - mse: 0.0470\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0461 - mse: 0.0461\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0443 - mse: 0.0443\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0435 - mse: 0.0435\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0427 - mse: 0.0427\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0419 - mse: 0.0419\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0403 - mse: 0.0403\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0395 - mse: 0.0395\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0388 - mse: 0.0388\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0380 - mse: 0.0380\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0373 - mse: 0.0373\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0352 - mse: 0.0352\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0339 - mse: 0.0339\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0332 - mse: 0.0332\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0326 - mse: 0.0326\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0314 - mse: 0.0314\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0308 - mse: 0.0308\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0302 - mse: 0.0302\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0296 - mse: 0.0296\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0285 - mse: 0.0285\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0269 - mse: 0.0269\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0244 - mse: 0.0244\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0239 - mse: 0.0239\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0222 - mse: 0.0222\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0217 - mse: 0.0217\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0151 - mse: 0.0151\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0142 - mse: 0.0142\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9792e-04 - mse: 9.9792e-04\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7889e-04 - mse: 9.7889e-04\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6022e-04 - mse: 9.6022e-04\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.4190e-04 - mse: 9.4190e-04\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2393e-04 - mse: 9.2393e-04\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.0631e-04 - mse: 9.0631e-04\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.8902e-04 - mse: 8.8902e-04\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7206e-04 - mse: 8.7206e-04\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.5543e-04 - mse: 8.5543e-04\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3911e-04 - mse: 8.3911e-04\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2311e-04 - mse: 8.2311e-04\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0741e-04 - mse: 8.0741e-04\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9200e-04 - mse: 7.9200e-04\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.7689e-04 - mse: 7.7689e-04\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6208e-04 - mse: 7.6208e-04\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.4754e-04 - mse: 7.4754e-04\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3328e-04 - mse: 7.3328e-04\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1929e-04 - mse: 7.1929e-04\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0557e-04 - mse: 7.0557e-04\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9212e-04 - mse: 6.9212e-04\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.7891e-04 - mse: 6.7891e-04\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.6596e-04 - mse: 6.6596e-04\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.5326e-04 - mse: 6.5326e-04\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4080e-04 - mse: 6.4080e-04\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2857e-04 - mse: 6.2857e-04\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.1658e-04 - mse: 6.1658e-04\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0483e-04 - mse: 6.0483e-04\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9329e-04 - mse: 5.9329e-04\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.8196e-04 - mse: 5.8196e-04\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7087e-04 - mse: 5.7087e-04\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.5998e-04 - mse: 5.5998e-04\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.4930e-04 - mse: 5.4930e-04\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3883e-04 - mse: 5.3883e-04\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2854e-04 - mse: 5.2854e-04\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1846e-04 - mse: 5.1846e-04\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0857e-04 - mse: 5.0857e-04\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.9887e-04 - mse: 4.9887e-04\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.8935e-04 - mse: 4.8935e-04\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8002e-04 - mse: 4.8002e-04\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.7086e-04 - mse: 4.7086e-04\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6188e-04 - mse: 4.6188e-04\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5307e-04 - mse: 4.5307e-04\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4443e-04 - mse: 4.4443e-04\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3595e-04 - mse: 4.3595e-04\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.2764e-04 - mse: 4.2764e-04\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1948e-04 - mse: 4.1948e-04\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1148e-04 - mse: 4.1148e-04\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0362e-04 - mse: 4.0362e-04\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9593e-04 - mse: 3.9593e-04\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8838e-04 - mse: 3.8838e-04\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8097e-04 - mse: 3.8097e-04\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7370e-04 - mse: 3.7370e-04\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.6657e-04 - mse: 3.6657e-04\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.5958e-04 - mse: 3.5958e-04\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5272e-04 - mse: 3.5272e-04\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4599e-04 - mse: 3.4599e-04\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.3939e-04 - mse: 3.3939e-04\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3292e-04 - mse: 3.3292e-04\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2657e-04 - mse: 3.2657e-04\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2035e-04 - mse: 3.2035e-04\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.1423e-04 - mse: 3.1423e-04\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.0824e-04 - mse: 3.0824e-04\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0236e-04 - mse: 3.0236e-04\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9659e-04 - mse: 2.9659e-04\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9093e-04 - mse: 2.9093e-04\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.8538e-04 - mse: 2.8538e-04\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7994e-04 - mse: 2.7994e-04\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7460e-04 - mse: 2.7460e-04\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6936e-04 - mse: 2.6936e-04\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6423e-04 - mse: 2.6423e-04\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5919e-04 - mse: 2.5919e-04\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5425e-04 - mse: 2.5425e-04\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4940e-04 - mse: 2.4940e-04\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4463e-04 - mse: 2.4463e-04\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3997e-04 - mse: 2.3997e-04\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3539e-04 - mse: 2.3539e-04\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3090e-04 - mse: 2.3090e-04\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2650e-04 - mse: 2.2650e-04\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2218e-04 - mse: 2.2218e-04\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1794e-04 - mse: 2.1794e-04\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1378e-04 - mse: 2.1378e-04\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0971e-04 - mse: 2.0971e-04\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0570e-04 - mse: 2.0570e-04\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0179e-04 - mse: 2.0179e-04\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9794e-04 - mse: 1.9794e-04\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9416e-04 - mse: 1.9416e-04\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9046e-04 - mse: 1.9046e-04\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8682e-04 - mse: 1.8682e-04\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.8326e-04 - mse: 1.8326e-04\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7976e-04 - mse: 1.7976e-04\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7634e-04 - mse: 1.7634e-04\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7297e-04 - mse: 1.7297e-04\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6967e-04 - mse: 1.6967e-04\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6643e-04 - mse: 1.6643e-04\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6326e-04 - mse: 1.6326e-04\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6015e-04 - mse: 1.6015e-04\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5709e-04 - mse: 1.5709e-04\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5409e-04 - mse: 1.5409e-04\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5116e-04 - mse: 1.5116e-04\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4827e-04 - mse: 1.4827e-04\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4545e-04 - mse: 1.4545e-04\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4267e-04 - mse: 1.4267e-04\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3995e-04 - mse: 1.3995e-04\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3728e-04 - mse: 1.3728e-04\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3466e-04 - mse: 1.3466e-04\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3209e-04 - mse: 1.3209e-04\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2957e-04 - mse: 1.2957e-04\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2710e-04 - mse: 1.2710e-04\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2468e-04 - mse: 1.2468e-04\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2230e-04 - mse: 1.2230e-04\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1997e-04 - mse: 1.1997e-04\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1768e-04 - mse: 1.1768e-04\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1543e-04 - mse: 1.1543e-04\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1323e-04 - mse: 1.1323e-04\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1107e-04 - mse: 1.1107e-04\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0895e-04 - mse: 1.0895e-04\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0688e-04 - mse: 1.0688e-04\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0484e-04 - mse: 1.0484e-04\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0284e-04 - mse: 1.0284e-04\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0087e-04 - mse: 1.0087e-04\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8949e-05 - mse: 9.8949e-05\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7063e-05 - mse: 9.7063e-05\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5212e-05 - mse: 9.5212e-05\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3396e-05 - mse: 9.3396e-05\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.1615e-05 - mse: 9.1615e-05\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9867e-05 - mse: 8.9867e-05\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.8153e-05 - mse: 8.8153e-05\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6472e-05 - mse: 8.6472e-05\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4823e-05 - mse: 8.4823e-05\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.3205e-05 - mse: 8.3205e-05\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.1616e-05 - mse: 8.1616e-05\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0060e-05 - mse: 8.0060e-05\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8532e-05 - mse: 7.8532e-05\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7035e-05 - mse: 7.7035e-05\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5563e-05 - mse: 7.5563e-05\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.4124e-05 - mse: 7.4124e-05\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.2711e-05 - mse: 7.2711e-05\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1321e-05 - mse: 7.1321e-05\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9961e-05 - mse: 6.9961e-05\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8630e-05 - mse: 6.8630e-05\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7318e-05 - mse: 6.7318e-05\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6032e-05 - mse: 6.6032e-05\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4774e-05 - mse: 6.4774e-05\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3539e-05 - mse: 6.3539e-05\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2326e-05 - mse: 6.2326e-05\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.1138e-05 - mse: 6.1138e-05\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9971e-05 - mse: 5.9971e-05\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.8827e-05 - mse: 5.8827e-05\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7708e-05 - mse: 5.7708e-05\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6606e-05 - mse: 5.6606e-05\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.5524e-05 - mse: 5.5524e-05\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.4467e-05 - mse: 5.4467e-05\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.3427e-05 - mse: 5.3427e-05\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2408e-05 - mse: 5.2408e-05\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.1410e-05 - mse: 5.1410e-05\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.0428e-05 - mse: 5.0428e-05\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9466e-05 - mse: 4.9466e-05\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8524e-05 - mse: 4.8524e-05\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.7597e-05 - mse: 4.7597e-05\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6688e-05 - mse: 4.6688e-05\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5799e-05 - mse: 4.5799e-05\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4923e-05 - mse: 4.4923e-05\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.4069e-05 - mse: 4.4069e-05\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3230e-05 - mse: 4.3230e-05\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.2404e-05 - mse: 4.2404e-05\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1595e-05 - mse: 4.1595e-05\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0801e-05 - mse: 4.0801e-05\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0023e-05 - mse: 4.0023e-05\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9260e-05 - mse: 3.9260e-05\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8511e-05 - mse: 3.8511e-05\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7777e-05 - mse: 3.7777e-05\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7055e-05 - mse: 3.7055e-05\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.6348e-05 - mse: 3.6348e-05\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.5655e-05 - mse: 3.5655e-05\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.4975e-05 - mse: 3.4975e-05\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.4308e-05 - mse: 3.4308e-05\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3654e-05 - mse: 3.3654e-05\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3012e-05 - mse: 3.3012e-05\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2382e-05 - mse: 3.2382e-05\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1765e-05 - mse: 3.1765e-05\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1159e-05 - mse: 3.1159e-05\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0565e-05 - mse: 3.0565e-05\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9982e-05 - mse: 2.9982e-05\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9409e-05 - mse: 2.9409e-05\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8848e-05 - mse: 2.8848e-05\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8299e-05 - mse: 2.8299e-05\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7759e-05 - mse: 2.7759e-05\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7229e-05 - mse: 2.7229e-05\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.6710e-05 - mse: 2.6710e-05\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6201e-05 - mse: 2.6201e-05\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5702e-05 - mse: 2.5702e-05\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5212e-05 - mse: 2.5212e-05\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4731e-05 - mse: 2.4731e-05\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4259e-05 - mse: 2.4259e-05\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3796e-05 - mse: 2.3796e-05\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.3342e-05 - mse: 2.3342e-05\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2896e-05 - mse: 2.2896e-05\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2459e-05 - mse: 2.2459e-05\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2032e-05 - mse: 2.2032e-05\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1610e-05 - mse: 2.1610e-05\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1199e-05 - mse: 2.1199e-05\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0795e-05 - mse: 2.0795e-05\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0398e-05 - mse: 2.0398e-05\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0008e-05 - mse: 2.0008e-05\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9628e-05 - mse: 1.9628e-05\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9254e-05 - mse: 1.9254e-05\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8886e-05 - mse: 1.8886e-05\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8525e-05 - mse: 1.8525e-05\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8172e-05 - mse: 1.8172e-05\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7825e-05 - mse: 1.7825e-05\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7486e-05 - mse: 1.7486e-05\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7152e-05 - mse: 1.7152e-05\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6825e-05 - mse: 1.6825e-05\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6504e-05 - mse: 1.6504e-05\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6188e-05 - mse: 1.6188e-05\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5879e-05 - mse: 1.5879e-05\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5577e-05 - mse: 1.5577e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,y, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ELcrfwfwARF6",
   "metadata": {
    "id": "ELcrfwfwARF6"
   },
   "source": [
    "As you can see, the loss went from `1.2677e-05` all the way down to `8.5635e-10`. If you run it again, these values may change. There are so many randomness involved in neural network training. Take an example, weights initialization is random. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8-GLhw7OA9_M",
   "metadata": {
    "id": "8-GLhw7OA9_M"
   },
   "source": [
    "<a name='2-5'></a>\n",
    "### 2.5  Evaluating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bBZxei-vzHAz",
   "metadata": {
    "id": "bBZxei-vzHAz"
   },
   "source": [
    "After we have trained the model, the next step is to evaluate it. \n",
    "\n",
    "But first off, we can plot the loss versus the epochs to see how it performed. Plotting the model metrics is a fundamental step in performing the error analysis. \n",
    "\n",
    "The training metric `mse` and `loss` are contained in `history.history` and the number of epochs are in `history.epoch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pSGWj1bK5jDN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "pSGWj1bK5jDN",
    "outputId": "90c7720f-351f-4400-a875-805eb4aeb5be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc125114990>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Plot loss vs epochs\n",
    "\n",
    "loss_df.plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VolEuUKs-LvT",
   "metadata": {
    "id": "VolEuUKs-LvT"
   },
   "source": [
    "There are cowple of things to note from the above graph. \n",
    "\n",
    "* First off, the loss and metric we are tracking are all similar. They are both `mean_squared_error` or `mse`.\n",
    "* The model had no improvement from 80(approx) epochs. This means that 500 epochs was too much, and instead of burning resources or compute power, we would have trained for fewer epochs since the model does not show a significant improvements in the later epochs. \n",
    "\n",
    "Training for many epochs beyond what's needed is usually the cause of `overfitting`. We will learn more about overfitting later, but simply, it's when the model is so good on the training set but very poor on the test set or the new data. So, in our case we are forcing the model to fit the data by training it too much. Overfitting can also be caused by using bigger models (for small dataset), etc...\n",
    "\n",
    "\n",
    "That said, let's make some predictions on unseen data. For simplicity, let's predict `y` of `X=30`. Remember that our equation is `y=2X+1`, so with x=30, y should be equal to `61`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "u1oA77b0__LG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1oA77b0__LG",
    "outputId": "bcb769cd-85ae-4ed5-dd4b-044a7721766c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61.015095]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([30.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iu2KiU4yA6pP",
   "metadata": {
    "id": "iu2KiU4yA6pP"
   },
   "source": [
    "Wow! That's so impressive. \n",
    "\n",
    "The model was able to determine the relationship between `X` and `y` and can use that relationship to predict `y` for unseen values of `X`. \n",
    "\n",
    "One thing to note that it is not guarranted to get the exact predictions, say 61. This is because there are so many randomness and probabilities involved behind the scene. \n",
    "\n",
    "\n",
    "One last thing we can try is to get the model parameters, that is weight and bias. And their values should be close to the coeffient and intercept of our linear equation, y=2X+1. 2 is coefficient(or weight), and 1 is the intercept(or bias). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b29uAewjCjB9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b29uAewjCjB9",
    "outputId": "a428ea97-e455-460e-8340-52a8fb60aad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.00069]], dtype=float32), array([0.9943954], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the model weights\n",
    "\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TR61EgS-C-yl",
   "metadata": {
    "id": "TR61EgS-C-yl"
   },
   "source": [
    "So, as you can see, the model learned that the relationship between X and y is `y=2.0008771 + 0.9928744` and this is very close to `y=2X+1`. Something intringuing here is that there is no where told the model such relationship - `it simply learned it observing the data that we provided`, and `this is the basis of the idea that machine learning is used to extract patterns in data`. \n",
    "\n",
    "With complex data, you might not get such intuition because there will be so many parameters, but in our case, the model was simple, the data was simple, and that allowed us to `uncover` the principal idea behind machine learning - `learning the relationship/pattern between the input features and labels, and using such relationship to make predictions on unseen data.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SjI67-vME-2y",
   "metadata": {
    "id": "SjI67-vME-2y"
   },
   "source": [
    "<a name='2-6'></a>\n",
    "### 2.6  Improving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FJNcx7oRFC-P",
   "metadata": {
    "id": "FJNcx7oRFC-P"
   },
   "source": [
    "Ideally, your model will likely not be good at the first. \n",
    "\n",
    "You will need to tweak some hyperparameters, or even improve the data. Also, there is a notion that [machine learning model is only 5% of what are to be done to ship a working machine learning system](https://jeande.medium.com/ml-model-is-5-what-should-we-be-doing-cd68ae14ad7f).  So, often, all you need is to improve the data than improving the model. There are even state of the art and open source models that you can take an advantages of if you have good data. And in those intances, building model will be out of the equation.  \n",
    "\n",
    "But ofcourse, improving the model and performing error analysis is not a trivial task and will depend on the results of the model on training and testing set. Here is some ideas that can guide you: \n",
    "\n",
    "* If the model is not doing well on the training data, it's a clue that the input data (X) doesn't contain the useful information needed to predict the output y. Or put it simply, the input features do not have `high predictive power`. The right thing to do here is to improve the data. Otherwise, the problem will perssit. \n",
    "\n",
    "* If the model is doing well on the training data but poorly on the testing data, it maybe that you overfitted the training data and that resulted in model failing to generalize on test/new data. Overfitting is one thing, there maybe other things not going well or worth improving. The right thing to do here is to plot the learning curve and see what's to be done based off what you are seeing.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eftCBSkUSCYV",
   "metadata": {
    "id": "eftCBSkUSCYV"
   },
   "source": [
    "Up to now, we have come a long way doing regression with neural networks. We have learned how to create a simple data, how to create, train, and compile a simple model, evaluating the results, and we saw some ideas on perfoming error analysis. \n",
    "\n",
    "We started simple with the goal of getting prepared to take a step further into real world scanerios. I wanted to jump quicky to bigger models and computer vision things but I remembered that quite often, it is understanding the basics that can set us off for understanding the bigger picture. \n",
    "\n",
    "To make it more exciting, let's not stop on linear equation (we could after all, we did regression already), but let's step into real world dataset, still practicing regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ce1AurnvUWUr",
   "metadata": {
    "id": "Ce1AurnvUWUr"
   },
   "source": [
    "<a name='3'></a>\n",
    "\n",
    "## 3. Going Beyond: A Real world dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MbhDb1hgWjy_",
   "metadata": {
    "id": "MbhDb1hgWjy_"
   },
   "source": [
    "Welome to the second part of the notebook, where we leap into real world scenarios. \n",
    "\n",
    "Still doing regression, we will use the real world forest dataset to predict the burned area of forest fires, in the northeast region of Portugal, by using meteorological and other data. \n",
    "\n",
    "You can learn more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/Forest+Fires)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_RplpeLNUYj0",
   "metadata": {
    "id": "_RplpeLNUYj0"
   },
   "source": [
    "<a name='3-1'></a>\n",
    "\n",
    "## 3.1 Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YFVMmxtm6R_a",
   "metadata": {
    "id": "YFVMmxtm6R_a"
   },
   "source": [
    "Before loading the dataset, I will first import all relevant imports. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JkG09wMBNVpf",
   "metadata": {
    "id": "JkG09wMBNVpf"
   },
   "source": [
    "Here are the information about the attributes: \n",
    "\n",
    "1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9 \n",
    "2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9 \n",
    "3. month - month of the year: 'jan' to 'dec' \n",
    "4. day - day of the week: 'mon' to 'sun' \n",
    "5. FFMC - FFMC index from the FWI system: 18.7 to 96.20 \n",
    "6. DMC - DMC index from the FWI system: 1.1 to 291.3 \n",
    "7. DC - DC index from the FWI system: 7.9 to 860.6 \n",
    "8. ISI - ISI index from the FWI system: 0.0 to 56.10 \n",
    "9. temp - temperature in Celsius degrees: 2.2 to 33.30 \n",
    "10. RH - relative humidity in %: 15.0 to 100 \n",
    "11. wind - wind speed in km/h: 0.40 to 9.40 \n",
    "12. rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    "13. area - the burned area of the forest (in ha): 0.00 to 1090.84 \n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/Forest+**Fires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "t4HzO0qP6ZyU",
   "metadata": {
    "id": "t4HzO0qP6ZyU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BWPs93SeGNrf",
   "metadata": {
    "id": "BWPs93SeGNrf"
   },
   "source": [
    "Let's download the dataset and load it into a Pandas dataframe using `pd.read_csv()`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "k6fog1WK9-bt",
   "metadata": {
    "id": "k6fog1WK9-bt"
   },
   "outputs": [],
   "source": [
    "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "\n",
    "forest_df = pd.read_csv(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mtdI1_o1G_6g",
   "metadata": {
    "id": "mtdI1_o1G_6g"
   },
   "source": [
    "Let's see the features and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "lZyX4Wg1G4ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZyX4Wg1G4ac",
    "outputId": "387e3cac-f2c0-4895-b8c5-5557df68d59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X       517 non-null    int64  \n",
      " 1   Y       517 non-null    int64  \n",
      " 2   month   517 non-null    object \n",
      " 3   day     517 non-null    object \n",
      " 4   FFMC    517 non-null    float64\n",
      " 5   DMC     517 non-null    float64\n",
      " 6   DC      517 non-null    float64\n",
      " 7   ISI     517 non-null    float64\n",
      " 8   temp    517 non-null    float64\n",
      " 9   RH      517 non-null    int64  \n",
      " 10  wind    517 non-null    float64\n",
      " 11  rain    517 non-null    float64\n",
      " 12  area    517 non-null    float64\n",
      "dtypes: float64(8), int64(3), object(2)\n",
      "memory usage: 52.6+ KB\n"
     ]
    }
   ],
   "source": [
    "forest_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mNrE3bEyJtP9",
   "metadata": {
    "id": "mNrE3bEyJtP9"
   },
   "source": [
    "The dataset contains 517 examples and 13 columns, 12 features and 1 label (`areas`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ufgJHWdhG-Rm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufgJHWdhG-Rm",
    "outputId": "5b334536-a20a-4e56-b7ea-82182dea3588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517, 13)\n"
     ]
    }
   ],
   "source": [
    "print(forest_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sxFGkjy8KqvN",
   "metadata": {
    "id": "sxFGkjy8KqvN"
   },
   "source": [
    "<a name='3-2'></a>\n",
    "\n",
    "## 3.2 Looking in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tF_IKN-JKyYI",
   "metadata": {
    "id": "tF_IKN-JKyYI"
   },
   "source": [
    "We will not go deep into analysis, but let's try to learn about the data we have. Before that, I will first split the dataset into training and test set. \n",
    "\n",
    "I will use Scikit-Learn `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dj61Dr0aKtfC",
   "metadata": {
    "id": "dj61Dr0aKtfC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(forest_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5H1K90wL-I2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5H1K90wL-I2",
    "outputId": "f57dbb02-8d00-4c7f-b77b-c3e975cf008c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training data: (361, 13)\n",
      "The shape of testing data: (156, 13)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of training data: {}\\nThe shape of testing data: {}'.format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rJLgRbRfLb91",
   "metadata": {
    "id": "rJLgRbRfLb91"
   },
   "source": [
    "Let's peep into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9G5OXBW_LYzA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "9G5OXBW_LYzA",
    "outputId": "4a155c14-d14a-424e-a91b-61f0cd6b712e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>sep</td>\n",
       "      <td>sun</td>\n",
       "      <td>92.4</td>\n",
       "      <td>105.8</td>\n",
       "      <td>758.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>24.8</td>\n",
       "      <td>28</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>sep</td>\n",
       "      <td>sat</td>\n",
       "      <td>91.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>744.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>47</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.2</td>\n",
       "      <td>110.9</td>\n",
       "      <td>537.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>43</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>92.1</td>\n",
       "      <td>152.6</td>\n",
       "      <td>658.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>58</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>jun</td>\n",
       "      <td>sat</td>\n",
       "      <td>53.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>233.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>90</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X  Y month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
       "311  6  3   sep  sun  92.4  105.8  758.1   9.9  24.8  28   1.8   0.0  14.29\n",
       "368  6  5   sep  sat  91.2   94.3  744.4   8.4  16.8  47   4.9   0.0  12.64\n",
       "23   7  4   aug  sat  90.2  110.9  537.4   6.2  19.5  43   5.8   0.0   0.00\n",
       "271  8  6   aug  tue  92.1  152.6  658.2  14.3  20.1  58   4.5   0.0   9.27\n",
       "299  6  5   jun  sat  53.4   71.0  233.8   0.4  10.6  90   2.7   0.0   0.00"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T6j7bE2qLywN",
   "metadata": {
    "id": "T6j7bE2qLywN"
   },
   "source": [
    "It seems that we have two categorical features, `month` and `day`. We will remember to encode them. For now we can see the number of samples in each month and later in each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01Ag_eK4MVxx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "01Ag_eK4MVxx",
    "outputId": "1bd8d799-8193-4d9c-87c7-e757539b01ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc1229df8d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['month'].value_counts().plot(kind='bar', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "LSRX1fskMajw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "LSRX1fskMajw",
    "outputId": "9001dda2-1716-4368-c3bd-924c8cbc4939"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc12050b410>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAE7CAYAAAASOb9BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUi0lEQVR4nO3dfbDld10f8PeHxAgiBQLbJRJgI2bCpK08XREE25JIixOHZCpDYRS3mnZbWxgotXa1Yx2qM4apBbHTwVkNuEUUwlMTiFIzWyiFMuBuSBEIaWBNSjJ5WJ4KAgWDn/5xfttcMrvZ870POefkvl4zd87v6eS+5ze5e97n9/D9VXcHAID5PWDRAQAAVo0CBQAwSIECABikQAEADFKgAAAGKVAAAINOvy9/2SMf+cjes2fPffkrAQA25MiRI5/r7l0nWnefFqg9e/bk8OHD9+WvBADYkKq6+WTrTnkKr6rOq6rr1v18uapeXlVnVtU1VXXj9PrwrY0NALCcTlmguvuG7n5Sdz8pyVOTfC3JO5PsT3Kou89NcmiaBwC43xu9iPzCJJ/p7puTXJzk4LT8YJJLtjIYAMCyGi1QL0zyB9P07u6+bZq+PcnuE72hqvZV1eGqOnzs2LENxgQAWB5zF6iqOiPJ85K89Z7revZE4hM+lbi7D3T3Wnev7dp1wgvZAQBWysgRqB9Ncm133zHN31FVZyXJ9HrnVocDAFhGIwXqRbn79F2SXJVk7zS9N8mVWxUKAGCZzVWgqurBSZ6T5B3rFl+W5DlVdWOSH5nmAQDu9+YaSLO7v5rkEfdY9vnM7soDANhRPAsPAGCQAgUAMOg+fRbeVtuz/+pFR7hXN1120aIjAADbwBEoAIBBChQAwCAFCgBgkAIFADBIgQIAGKRAAQAMUqAAAAYpUAAAgxQoAIBBChQAwCAFCgBgkAIFADBIgQIAGKRAAQAMUqAAAAYpUAAAgxQoAIBBChQAwCAFCgBgkAIFADBIgQIAGKRAAQAMUqAAAAYpUAAAgxQoAIBBChQAwKC5ClRVPayq3lZVn6qq66vqGVV1ZlVdU1U3Tq8P3+6wAADLYN4jUK9N8p7ufkKSJya5Psn+JIe6+9wkh6Z5AID7vVMWqKp6aJK/meTyJOnub3b3l5JcnOTgtNnBJJdsV0gAgGVy+hzbnJPkWJI3VNUTkxxJ8rIku7v7tmmb25PsPtGbq2pfkn1J8tjHPnbTgdkae/ZfvegI9+qmyy5adAQAOKl5TuGdnuQpSV7X3U9O8tXc43Rdd3eSPtGbu/tAd69199quXbs2mxcAYOHmKVC3JLmluz88zb8ts0J1R1WdlSTT653bExEAYLmcskB19+1JPltV502LLkzyySRXJdk7Ldub5MptSQgAsGTmuQYqSV6a5E1VdUaSo0l+OrPydUVVXZrk5iQv2J6IAADLZa4C1d3XJVk7waoLtzYOAMDyMxI5AMAgBQoAYNC810AB6xhHC2BncwQKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMOj0RQcAdp49+69edIR7ddNlFy06ArDkHIECABikQAEADFKgAAAGKVAAAIMUKACAQQoUAMAgBQoAYNBc40BV1U1JvpLkW0nu6u61qjozyVuS7ElyU5IXdPcXtycmAMDyGDkC9ezuflJ3r03z+5Mc6u5zkxya5gEA7vc2cwrv4iQHp+mDSS7ZfBwAgOU3b4HqJH9cVUeqat+0bHd33zZN355k94neWFX7qupwVR0+duzYJuMCACzevM/Ce1Z331pVfzXJNVX1qfUru7urqk/0xu4+kORAkqytrZ1wGwCAVTLXEajuvnV6vTPJO5M8LckdVXVWkkyvd25XSACAZXLKAlVVD66qhxyfTvJ3knw8yVVJ9k6b7U1y5XaFBABYJvOcwtud5J1VdXz73+/u91TVnyS5oqouTXJzkhdsX0wAgOVxygLV3UeTPPEEyz+f5MLtCAUAsMyMRA4AMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDTl90AADG7Nl/9aIjnNRNl1206Ahwn3AECgBgkAIFADBIgQIAGKRAAQAMUqAAAAYpUAAAgxQoAIBBc48DVVWnJTmc5Nbu/rGqOifJm5M8IsmRJC/u7m9uT0wA2LxlHkMrMY7WKhk5AvWyJNevm39Vktd09/cl+WKSS7cyGADAspqrQFXV2UkuSvI703wluSDJ26ZNDia5ZDsCAgAsm3mPQP1Gkp9P8pfT/COSfKm775rmb0ny6C3OBgCwlE5ZoKrqx5Lc2d1HNvILqmpfVR2uqsPHjh3byH8CAGCpzHME6plJnldVN2V20fgFSV6b5GFVdfwi9LOT3HqiN3f3ge5e6+61Xbt2bUFkAIDFOmWB6u5f6O6zu3tPkhcm+a/d/RNJ3pvk+dNme5NcuW0pAQCWyGbGgfpXSV5RVZ/O7Jqoy7cmEgDAcpt7HKgk6e73JXnfNH00ydO2PhIAwHIzEjkAwCAFCgBg0NApPABg5/IonLs5AgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYdMoCVVUPrKqPVNX/rKpPVNUrp+XnVNWHq+rTVfWWqjpj++MCACzePEegvpHkgu5+YpInJXluVT09yauSvKa7vy/JF5Ncun0xAQCWxykLVM/8+TT7HdNPJ7kgydum5QeTXLItCQEAlsxc10BV1WlVdV2SO5Nck+QzSb7U3XdNm9yS5NHbExEAYLnMVaC6+1vd/aQkZyd5WpInzPsLqmpfVR2uqsPHjh3bYEwAgOUxdBded38pyXuTPCPJw6rq9GnV2UluPcl7DnT3Wnev7dq1a1NhAQCWwTx34e2qqodN0w9K8pwk12dWpJ4/bbY3yZXbFRIAYJmcfupNclaSg1V1WmaF64rufndVfTLJm6vqV5N8NMnl25gTAGBpnLJAdffHkjz5BMuPZnY9FADAjmIkcgCAQQoUAMAgBQoAYJACBQAwSIECABikQAEADFKgAAAGKVAAAIMUKACAQQoUAMAgBQoAYJACBQAwSIECABikQAEADFKgAAAGKVAAAIMUKACAQQoUAMAgBQoAYJACBQAwSIECABikQAEADFKgAAAGKVAAAIMUKACAQQoUAMAgBQoAYJACBQAwSIECABh0ygJVVY+pqvdW1Ser6hNV9bJp+ZlVdU1V3Ti9Pnz74wIALN48R6DuSvIvuvv8JE9P8s+q6vwk+5Mc6u5zkxya5gEA7vdOWaC6+7buvnaa/kqS65M8OsnFSQ5Omx1Mcsl2hQQAWCZD10BV1Z4kT07y4SS7u/u2adXtSXZvaTIAgCU1d4Gqqu9O8vYkL+/uL69f192dpE/yvn1VdbiqDh87dmxTYQEAlsFcBaqqviOz8vSm7n7HtPiOqjprWn9WkjtP9N7uPtDda929tmvXrq3IDACwUPPchVdJLk9yfXe/et2qq5Lsnab3Jrly6+MBACyf0+fY5plJXpzkT6vqumnZLya5LMkVVXVpkpuTvGB7IgIALJdTFqju/kCSOsnqC7c2DgDA8jMSOQDAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAw6ZYGqqtdX1Z1V9fF1y86sqmuq6sbp9eHbGxMAYHnMcwTqd5M89x7L9ic51N3nJjk0zQMA7AinLFDd/f4kX7jH4ouTHJymDya5ZItzAQAsrY1eA7W7u2+bpm9PsnuL8gAALL1NX0Te3Z2kT7a+qvZV1eGqOnzs2LHN/joAgIXbaIG6o6rOSpLp9c6TbdjdB7p7rbvXdu3atcFfBwCwPDZaoK5Ksnea3pvkyq2JAwCw/OYZxuAPknwoyXlVdUtVXZrksiTPqaobk/zINA8AsCOcfqoNuvtFJ1l14RZnAQBYCUYiBwAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEEKFADAIAUKAGCQAgUAMEiBAgAYpEABAAxSoAAABilQAACDFCgAgEGbKlBV9dyquqGqPl1V+7cqFADAMttwgaqq05L8xyQ/muT8JC+qqvO3KhgAwLLazBGopyX5dHcf7e5vJnlzkou3JhYAwPLaTIF6dJLPrpu/ZVoGAHC/Vt29sTdWPT/Jc7v7H07zL07yg939kntsty/Jvmn2vCQ3bDzutntkks8tOsSKsu82x/7bHPtvc+y/jbPvNmfZ99/junvXiVacvon/6K1JHrNu/uxp2bfp7gNJDmzi99xnqupwd68tOscqsu82x/7bHPtvc+y/jbPvNmeV999mTuH9SZJzq+qcqjojyQuTXLU1sQAAlteGj0B1911V9ZIk/yXJaUle392f2LJkAABLajOn8NLdf5jkD7coyzJYiVONS8q+2xz7b3Psv82x/zbOvtucld1/G76IHABgp/IoFwCAQQoUAMAgBQoWpKq+c55lACyfHV+gquq0qvqeqnrs8Z9FZ2LH+NCcyzgJf78bU1W7q+ryqvqjaf78qrp00blglWzqLrxVV1UvTfLLSe5I8pfT4k7y/QsLtQKq6je6++VV9a7M9te36e7nLSDWyqiqR2X22KMHVdWTk9S06q8k+a6FBVsx/n435XeTvCHJv57m/1eStyS5fFGBVkVVvTcn/nfvggXEWRkn+7w4bhU/N3Z0gUrysiTndffnFx1kxbxxev31haZYXX83yT/IbPT+V69b/pUkv7iIQCvK3+/GPbK7r6iqX0j+/7h+31p0qBXxc+umH5jkx5PctaAsq+T458XfS/KoJL83zb8osy9BK2enF6jPJvk/iw6xarr7SFWdlmRfd//EovOsmu4+mORgVf14d7990XlWmL/fjftqVT0i0xGBqnp67Mu5dPeReyz6YFV9ZCFhVkh3/7ckqap/f49Ht7yrqg4vKNam7PQCdTTJ+6rq6iTfOL6wu1998reQJN39rap6XFWd0d3fXHSeVdTdb6+qi5L8tcy+yR5f/m8Xl2ql+PvduFdk9uitx1fVB5PsSvL8xUZaDVV15rrZByR5apKHLijOKnpwVX1vdx9Nkqo6J8mDF5xpQ3Z6gfrf088Z0w9jjmb27euqJF89vtAH2Hyq6rcyu+bp2Ul+J7MPMN9k5+fvd4O6+9qq+ltJzsvsGrwbuvsvFhxrVRzJ7MhdZXbq7s+SuAB/fv88sy8+RzPbh49L8o8XG2ljjETOsKp6Y3e/uKq+lOQ191zf3a9cQKyVU1Uf6+7vX/f63Un+qLt/eNHZVsm039Ldf77oLKuiqn7qRMu7+z/d11nYeabhWp4wzX6qu79xb9svqx19BMrdFBv21Kr6nsy+/f+HRYdZYf93ev3atD+/kOSsBeZZKVX11zO7oeHMaf5zSX7KQ83n8gPrph+Y5MIk1yZRoOZQVT+UZE/WfYYqn/Opqu/K7BTy47r7H1XVuVV1Xne/e9HZRu3oAhV3U2zUbyU5lOScJOsv/qvMCun3LiLUCnpXVT0syb/L7MOrk/z2YiOtlANJXtHd702Sqvrbme2/H1pkqFXQ3S9dPz/9f/jmBcVZKVX1xiSPT3JdkuN3LnaUz3m9IbPToM+Y5m9N8tYkCtQqcTfFxnT3byb5zap6XXf/7KLzrLBPJfnWdDH5+UmekuQ/LzjTKnnw8fKUJN39vqpayYtRl8BX44vPvNaSnN+uf9mox3f336+qFyVJd3+tqupUb1pGO7pAneBuirW4m2JuytOm/VJ3v7WqnpXkgszGSXldkh9cbKyVcbSqfil3j0v2k5nd2MApTDd+HPeAJOcnuWJBcVbNxzMbx+i2RQdZUd+sqgfl7iE0Hp91d9Gukh1doPLtd1P8RZKb4m4K7jvHD/9flOS3u/vqqvrVRQZaMT+T5JVJjo+l9d+T/PTi4qyURyX5l9P0XZldz/iSxcVZfutG0n5Ikk9OZyvWD5+xciNpL8gvJ3lPksdU1ZuSPDOzgYVXzo6+C6+qXpDkPd395emb7FOS/Ep3X7vgaOwAVfXuzM7/Pyez//e+nuQj3f3EhQZbEVW1ltmjSPbk7i+D3d0e5XIKVXVtdz/lHss+Zt+d3DTsQyV5VZKfX78qyau625HjOVTV7yX5WGb/3h1N8uHu/txiU23MTi9Qx28ff1aSX8nsFMq/8YfAfWG6G+W5Sf60u2+sqrOS/I3u/uMFR1sJVXVDZjeCfDx3Pwsv3X3zwkItuar62ST/NLPrnT6zbtVDknywu39yIcFWiPK5OVX17CQ/PP08PslHk7y/u1+70GAbsNML1Ee7+8lV9WuZfYj9/vFli84G3Luq+kB3P2vROVZJVT00ycOT/FqS/etWfaW7v7CYVKtB+dw606PAfiCzQYT/SZKvd/cT7v1dy2enFyinUGBFVdWFmT2I9FC+/VqUdywsFPdbyufWqKpDmT265UOZXbf4ge6+c7GpNmanFyinUGBFTddSPCHJJ3L3Kbzu7p9ZXCrg3lTVazJ7fuA3knwwyfuTfKi7v77QYBuwowsUsLqq6obuPm/ROYBxVfWQzO6++7kkj+ru71xsonE7fRgDYHX9j6o6v7s/ueggwHyq6iWZXUD+1MyGDnp9ZqfyVo4CBayqpye5rqr+LLPTARXDGMCye2CSVyc50t0r/eg0p/CAlVRVjzvRcsMYAPcFBQoAYNADFh0AAGDVKFAAAIMUKACAQQoUAMAgBQoAYND/A6BZ8GnAYp/1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['day'].value_counts().plot(kind='bar', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uPDQxTMzO7xu",
   "metadata": {
    "id": "uPDQxTMzO7xu"
   },
   "source": [
    "We can also check the distribution of the area. Area is very skewed, you can see that most values are very close to zero. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "VIIQnLdQPCUX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "VIIQnLdQPCUX",
    "outputId": "db361c5f-e6d0-43d3-852d-cd0463ecef67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc1204ac5d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=train_data, x='area', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mr_SUbRXSTiB",
   "metadata": {
    "id": "Mr_SUbRXSTiB"
   },
   "source": [
    "<a name='3-3'></a>\n",
    "\n",
    "## 3.3 Preparing the Data for the Model\n",
    "\n",
    "Here we will do two things, one is to normalize numerical features and the second is to encode categorical features. We can set up a pipeline to handle that. \n",
    "\n",
    "For simplicity, we will use Scikit-Learn processing functions. \n",
    "\n",
    "I will first separate features and label. We can use a function that can also be applied to test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fHdD4ND8klK",
   "metadata": {
    "id": "4fHdD4ND8klK"
   },
   "outputs": [],
   "source": [
    "def get_feats_and_labels(data, label):\n",
    "  \"\"\" Take data and label as inputs, return features and labels separated \"\"\"\n",
    "\n",
    "  data_feats = data.drop(label, axis=1)\n",
    "  data_label = data[label]\n",
    "\n",
    "  return data_feats, data_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w2xPKoSO9bI9",
   "metadata": {
    "id": "w2xPKoSO9bI9"
   },
   "source": [
    "Let's use the function created above to get the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ruS-krcN81nA",
   "metadata": {
    "id": "ruS-krcN81nA"
   },
   "outputs": [],
   "source": [
    "train_feats, train_label = get_feats_and_labels(train_data, 'area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "-LC74aAlSaOJ",
   "metadata": {
    "id": "-LC74aAlSaOJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "\n",
    "# The column transformer requires lists of features\n",
    "\n",
    "num_feats = ['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH',\n",
    "       'wind', 'rain']\n",
    "cat_feats = ['month', 'day']\n",
    "\n",
    "# define the pipeline to scale the numeric features and handle categorical features\n",
    "final_pipe = ColumnTransformer([\n",
    "   ('num',scaler , num_feats),    \n",
    "   ('cat', encoder , cat_feats)                        \n",
    "\n",
    "])\n",
    "\n",
    "training_data_prepared = final_pipe.fit_transform(train_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tYog2gmfWhzq",
   "metadata": {
    "id": "tYog2gmfWhzq"
   },
   "source": [
    "Now, we can see the shape of the transformed dataset. It is a NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "I7nb6z5kWAXf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7nb6z5kWAXf",
    "outputId": "c0ac5b79-f42d-4e3f-9e08-e4ffa6c10ee0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 12)"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "gom2N0zkW6Me",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gom2N0zkW6Me",
    "outputId": "44336017-3919-4ee6-80e8-364a58ce75e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loeQqU-v1aoo",
   "metadata": {
    "id": "loeQqU-v1aoo"
   },
   "source": [
    "Also let's tranform the test set. Note that for the test set, we don't `fit_transform()`. \n",
    "\n",
    "I will get the features and labels separated first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "NkI8fXYS1vXp",
   "metadata": {
    "id": "NkI8fXYS1vXp"
   },
   "outputs": [],
   "source": [
    "test_feats, test_label = get_feats_and_labels(test_data, 'area')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rbq6pgYG2GGt",
   "metadata": {
    "id": "Rbq6pgYG2GGt"
   },
   "source": [
    "And now we transform the test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "lldqbz9-2M_S",
   "metadata": {
    "id": "lldqbz9-2M_S"
   },
   "outputs": [],
   "source": [
    "test_data_prepared = final_pipe.transform(test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J_rggNrUG92O",
   "metadata": {
    "id": "J_rggNrUG92O"
   },
   "source": [
    "Let's convert train and test labels to NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "CiO8zTLNGR3x",
   "metadata": {
    "id": "CiO8zTLNGR3x"
   },
   "outputs": [],
   "source": [
    "train_label = train_label.to_numpy()\n",
    "test_label = test_label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gKG6nbrJXOza",
   "metadata": {
    "id": "gKG6nbrJXOza"
   },
   "source": [
    "<a name='3-4'></a>\n",
    "\n",
    "## 3.4 Creating, Compiling and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-ckljbee4qxZ",
   "metadata": {
    "id": "-ckljbee4qxZ"
   },
   "source": [
    "Now that our data is prepared, it's time to create a neural network regressor. \n",
    "\n",
    "Like in the first example, we will use the [Sequential API](https://keras.io/api/models/sequential/). \n",
    "\n",
    "Everytime we are creating a model in TensorFlow, we have to specify the input shape. In this example, the input shape will be:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ttRc3aELAAnO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttRc3aELAAnO",
    "outputId": "fef6b556-f396-4cca-d980-31e8d7890e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = training_data_prepared.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "G8DZ4p9_XZbi",
   "metadata": {
    "id": "G8DZ4p9_XZbi"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "                                 \n",
    "            # The first layers must specify the input shape always\n",
    "            keras.layers.Dense(12, activation='relu', input_shape=input_shape),\n",
    "            keras.layers.Dense(24, activation='relu'),\n",
    "\n",
    "            # The last layer usually doesn't have activation function in regression\n",
    "            keras.layers.Dense(1)                \n",
    "\n",
    "])\n",
    "\n",
    "# Now we compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hARZnzj5CuhL",
   "metadata": {
    "id": "hARZnzj5CuhL"
   },
   "source": [
    "Let's see the model summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "hkPDJF9TCxEb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkPDJF9TCxEb",
    "outputId": "fb72cbb2-3852-4b7b-bf59-7bf827658824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 493\n",
      "Trainable params: 493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AIuSKB93Bk2S",
   "metadata": {
    "id": "AIuSKB93Bk2S"
   },
   "source": [
    "Remember, when the model is created in TensorFlow, it is like an empty graphs. We can even visualize it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "gyxUlkxGBvUD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "gyxUlkxGBvUD",
    "outputId": "ea494afb-32e2-44a2-f273-c25f8a9b8f7a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHunKbu3CQYt",
   "metadata": {
    "id": "ZHunKbu3CQYt"
   },
   "source": [
    "Before training or fitting the model to the data, a model is nothing other than empty graphs. \n",
    "\n",
    "Now let's train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "KS3MtZzeCoHE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KS3MtZzeCoHE",
    "outputId": "53d7a9f1-2d7f-400b-f7cb-e2c1ee8dcff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2469.2397 - val_loss: 8134.5859\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2459.2871 - val_loss: 8118.8228\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2450.7903 - val_loss: 8103.8804\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2441.6943 - val_loss: 8089.2666\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2434.0076 - val_loss: 8072.9697\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2424.5598 - val_loss: 8058.1284\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2415.4243 - val_loss: 8043.0474\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2408.8987 - val_loss: 8027.8652\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2400.1633 - val_loss: 8016.6123\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2394.5269 - val_loss: 8002.1450\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2387.1274 - val_loss: 7992.6460\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2381.7930 - val_loss: 7977.2622\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2374.9229 - val_loss: 7964.3071\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2369.6033 - val_loss: 7950.7603\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2363.9551 - val_loss: 7944.3311\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2360.1489 - val_loss: 7940.5791\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2357.5649 - val_loss: 7931.1465\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2352.6367 - val_loss: 7928.5425\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2349.8198 - val_loss: 7929.9912\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2348.3557 - val_loss: 7922.7339\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2344.6016 - val_loss: 7923.1060\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2342.2639 - val_loss: 7924.5825\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2340.2104 - val_loss: 7926.3301\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2337.6282 - val_loss: 7923.0034\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2335.4111 - val_loss: 7922.9038\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2333.2837 - val_loss: 7924.2603\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2331.5825 - val_loss: 7927.1953\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2329.1016 - val_loss: 7927.0884\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2327.0312 - val_loss: 7928.7388\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2324.4333 - val_loss: 7928.5186\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2323.7446 - val_loss: 7930.0737\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2320.0112 - val_loss: 7929.5078\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2318.2605 - val_loss: 7929.9624\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2316.4971 - val_loss: 7933.8188\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2314.5596 - val_loss: 7929.4912\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2310.0752 - val_loss: 7931.4111\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2309.5459 - val_loss: 7931.3701\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2305.5598 - val_loss: 7929.4160\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2303.5889 - val_loss: 7930.8564\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2301.1873 - val_loss: 7930.4663\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2298.8359 - val_loss: 7931.1299\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2296.8936 - val_loss: 7929.3472\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2293.8757 - val_loss: 7931.6821\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2291.9534 - val_loss: 7934.3374\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2290.0776 - val_loss: 7935.1626\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2286.5276 - val_loss: 7934.0923\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2284.9331 - val_loss: 7938.9839\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2281.0420 - val_loss: 7940.3989\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2279.7737 - val_loss: 7941.1084\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2277.2446 - val_loss: 7943.4912\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_data_prepared, train_label, \n",
    "                    validation_data = (test_data_prepared, test_label), epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fZD8FlqtEPfT",
   "metadata": {
    "id": "fZD8FlqtEPfT"
   },
   "source": [
    "<a name='3-5'></a>\n",
    "\n",
    "## 3.5 Evaluating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TUOlu65YEif6",
   "metadata": {
    "id": "TUOlu65YEif6"
   },
   "source": [
    "After we have trained the model, the next step is to evaluate it. \n",
    "\n",
    "But first off, we can plot the loss versus the epochs to see how it performed. Plotting the model metrics is a fundamental step in performing the error analysis. \n",
    "\n",
    "`loss` and `val_loss` are contained in `history.history` and the number of epochs are in `history.epoch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "yMg2Zo3rEif-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "yMg2Zo3rEif-",
    "outputId": "57b051d9-d03d-4295-a6a3-4229d54229d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc11db0e690>"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Plot loss vs epochs\n",
    "\n",
    "loss_df.plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "q2co33ICNWKo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2co33ICNWKo",
    "outputId": "4de0e3ae-8618-46f2-b291-be53474418d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 7943.4912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7943.4912109375"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data_prepared, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nyhlBiJeGDoS",
   "metadata": {
    "id": "nyhlBiJeGDoS"
   },
   "source": [
    "The results are quite awful. Let's try to think why the model is not doing well. There are some few things to draw from the graph above. \n",
    "\n",
    "* Ideally, both validation and training loss should decrease during training. If training doesn't decrease, it's very likely that the input features don't contain enough information to predict the output. \n",
    "\n",
    "* Both `loss` and `val_loss` didn't improve alot, and there is no evidence that training for more epochs will improve the results. Quite the opposite, there is evidence that it will not improve.\n",
    "\n",
    "* How about adding more layers, or neurons? There is a notion that a model is as good as the data it was trained on. The sure thing to do here is to improve the data. \n",
    "\n",
    "One might argue that everything should work perfectly, but I don't see a point of always using datasets that you will will always work. In some scenarios, that's fine. \n",
    "\n",
    "But the aim of this labs and other previous/later labs is to introduce you to uncommon datasets wherever possible. If something doesn't work, you will learn why it doesn't work and what can be done to make it work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bhEnsQqNEmS",
   "metadata": {
    "id": "6bhEnsQqNEmS"
   },
   "source": [
    "<a name='3-6'></a>\n",
    "\n",
    "## 3.6 Saving and Loading a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BoN-N6yNNMqK",
   "metadata": {
    "id": "BoN-N6yNNMqK"
   },
   "source": [
    "I something went well, from training to evaluating to improving a model, you would want to save it. \n",
    "\n",
    "Here is how to save a model and how to load a saved model. The model will be saved in HDF5 `format`. When the model is saved in such format, the whole model things are saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "mo-NVNHRNIp0",
   "metadata": {
    "id": "mo-NVNHRNIp0"
   },
   "outputs": [],
   "source": [
    "model.save('forest_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "htzej8JaOwiB",
   "metadata": {
    "id": "htzej8JaOwiB"
   },
   "source": [
    "And loading the model is simple too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ZBPS83dOvXA",
   "metadata": {
    "id": "2ZBPS83dOvXA"
   },
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('forest_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UncTnf4sQEcF",
   "metadata": {
    "id": "UncTnf4sQEcF"
   },
   "source": [
    "If you were building a website for instance, you can save a model and load it to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JL1emoFCQ3v2",
   "metadata": {
    "id": "JL1emoFCQ3v2"
   },
   "source": [
    "<a name='3-7'></a>\n",
    "\n",
    "## 3.7 Final Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03YHhwcrQ-pC",
   "metadata": {
    "id": "03YHhwcrQ-pC"
   },
   "source": [
    "It has been a quite long journey, from fitting a straight line to building a neural network for a real world dataset. \n",
    "\n",
    "Ideally, for all datasets we used, neural networks would not be a suitable model. But because we are learning, it makes sense to start simple for the sake of understanding the latter. \n",
    "\n",
    "In the next lab, we will do classification with neural networks. Later we will go deep into areas that neural networks have shown potential such as computer vision and natural language processing, and that's where we will practice all possible techniques of improving the results of the neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xwl8zemTSVx2",
   "metadata": {
    "id": "Xwl8zemTSVx2"
   },
   "source": [
    "## [BACK TO TOP](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6EuyW3AVSbL4",
   "metadata": {
    "id": "6EuyW3AVSbL4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7.3 Neural Networks for Regression with TensorFlow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
